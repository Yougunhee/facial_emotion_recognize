{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pympler.asizeof import asizeof\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkdir = \"./save\"\n",
    "def one_hot(s):\n",
    "    arr = np.zeros(7,np.uint8)\n",
    "    arr[int(s)]=1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 7) , label 완료\n"
     ]
    }
   ],
   "source": [
    "all_label = np.loadtxt('all_label.txt', dtype=np.uint8)\n",
    "#one-hot encoding\n",
    "print(np.shape(all_label), \", label 완료\")\n",
    "all_data = np.loadtxt('all_data.txt', dtype=np.uint8)\n",
    "\n",
    "last_epoch = tf.Variable(0, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.001, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, c_in, c_out, kernel_size = [3,3], bn = True, pad = True):\n",
    "    w = weight_variable([*kernel_size, c_in, c_out])\n",
    "    b = bias_variable([c_out])\n",
    "    p = \"SAME\" if pad else \"VALID\"\n",
    "    c = tf.nn.conv2d(x, w, [1,1,1,1], p) + b\n",
    "    if bn is True:\n",
    "        c = tf.contrib.layers.batch_norm(c)\n",
    "    return tf.nn.relu(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_pool(x, kernel_size = [2,2]):\n",
    "    return tf.nn.max_pool(x, [1, *kernel_size, 1], [1, *kernel_size, 1], \"VALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 2304])\n",
    "y_ = tf.placeholder(tf.float32, shape = [None, 7])\n",
    "\n",
    "X_img = tf.reshape(X,[-1,48,48,1])\n",
    "\n",
    "conv1 = conv2d(X_img, 1, 64)\n",
    "conv2 = conv2d(conv1, 64, 64)\n",
    "pool3 = max_pool(conv2)\n",
    "\n",
    "conv4 = conv2d(pool3, 64, 128)\n",
    "conv5 = conv2d(conv4, 128, 128)\n",
    "conv6 = conv2d(conv5, 128, 128)\n",
    "pool7 = max_pool(conv6)\n",
    "\n",
    "conv8 = conv2d(pool7, 128, 256)\n",
    "conv9 = conv2d(conv8, 256, 256)\n",
    "conv10 = conv2d(conv9, 256, 256)\n",
    "pool11 = max_pool(conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat = tf.reshape(pool11, [-1,6*6*256])\n",
    "\n",
    "w4 = weight_variable([6*6*256, 2048])\n",
    "b4 = bias_variable([2048])\n",
    "layer4 = tf.nn.relu(tf.matmul(flat,w4)+b4)\n",
    "\n",
    "w5 = weight_variable([2048, 1000])\n",
    "b5 = bias_variable([1000])\n",
    "layer5 = tf.nn.relu(tf.matmul(layer4,w5)+b5)\n",
    "\n",
    "w6 = weight_variable([1000,7])\n",
    "b6 = bias_variable([7])\n",
    "y_conv = tf.matmul(layer5,w6)+b6\n",
    "\n",
    "y_loss= tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-2).minimize(y_loss)\n",
    "y_class = tf.argmax(y_conv,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th epoch,  0 th batch 1.88531\n",
      "0 th epoch,  20 th batch 1.5988\n",
      "0 th epoch,  40 th batch 1.59218\n",
      "0 th epoch,  60 th batch 1.6475\n",
      "0 th epoch,  80 th batch 1.56554\n",
      "0 th epoch,  100 th batch 1.63134\n",
      "0 th epoch,  120 th batch 1.55133\n",
      "0 th epoch,  140 th batch 1.64924\n",
      "0 th epoch,  160 th batch 1.60944\n",
      "0 th epoch,  180 th batch 1.58627\n",
      "0 th epoch,  200 th batch 1.43303\n",
      "0 th epoch,  220 th batch 1.42619\n",
      "0 th epoch,  240 th batch 1.36356\n",
      "0 th epoch,  260 th batch 1.30206\n",
      "0 th epoch,  280 th batch 1.37138\n",
      "0 th epoch,  300 th batch 1.51208\n",
      "0 th epoch,  320 th batch 1.30178\n",
      "0 th epoch,  340 th batch 1.26624\n",
      "0 th epoch,  360 th batch 1.1909\n",
      "0 th epoch,  380 th batch 1.32524\n",
      "0 th epoch,  400 th batch 1.24332\n",
      "0 th epoch,  420 th batch 1.26535\n",
      "0 th epoch,  440 th batch 1.41811\n",
      "0 th epoch,  460 th batch 1.31285\n",
      "0 th epoch,  480 th batch 1.23146\n",
      "0 th epoch,  500 th batch 1.2455\n",
      "0 th epoch,  520 th batch 0.860223\n",
      "0 th epoch,  540 th batch 1.06899\n",
      "0 th epoch,  560 th batch 1.08536\n",
      "0 th epoch,  580 th batch 1.17945\n",
      "0 th epoch,  600 th batch 1.30071\n",
      "0 th epoch,  620 th batch 0.760407\n",
      "0 th epoch,  640 th batch 1.3021\n",
      "0 th epoch,  660 th batch 1.16772\n",
      "0 th epoch,  680 th batch 1.08218\n",
      "0 th epoch,  700 th batch 1.1876\n",
      "0 th epoch,  720 th batch 1.24154\n",
      "0 th epoch,  740 th batch 1.09173\n",
      "0 th epoch,  760 th batch 0.844622\n",
      "0 th epoch,  780 th batch 0.969832\n",
      "0 th epoch,  800 th batch 1.1745\n",
      "0 th epoch,  820 th batch 1.23485\n",
      "0 th epoch,  840 th batch 1.26496\n",
      "0 th epoch,  860 th batch 0.890703\n",
      "0 th epoch,  880 th batch 0.693674\n",
      "0 th epoch,  900 th batch 1.07425\n",
      "0 th epoch,  920 th batch 0.873156\n",
      "0 th epoch,  940 th batch 1.19323\n",
      "0 th epoch,  960 th batch 1.09438\n",
      "0 th epoch,  980 th batch 1.18353\n",
      "0 th epoch,  1000 th batch 1.01659\n",
      "0 th epoch,  1020 th batch 0.819991\n",
      "0 th epoch,  1040 th batch 1.07481\n",
      "0 th epoch,  1060 th batch 0.986464\n",
      "0 th epoch,  1080 th batch 1.03658\n",
      "0 th epoch,  1100 th batch 0.888541\n",
      "0 th epoch,  1120 th batch 0.898858\n",
      "0 th epoch,  1140 th batch 0.568095\n",
      "0 th epoch,  1160 th batch 0.884888\n",
      "0 th epoch,  1180 th batch 0.968707\n",
      "0 th epoch,  1200 th batch 0.804049\n",
      "0 th epoch,  1220 th batch 0.977499\n",
      "0 th epoch,  1240 th batch 1.0836\n",
      "0 th epoch,  1260 th batch 0.837352\n",
      "0 th epoch,  1280 th batch 1.13318\n",
      "0 th epoch,  1300 th batch 1.00948\n",
      "0 th epoch,  1320 th batch 0.711013\n",
      "0 th epoch,  1340 th batch 0.696993\n",
      "0 th epoch,  1360 th batch 1.02675\n",
      "0 th epoch,  1380 th batch 0.826279\n",
      "0 th epoch,  1400 th batch 0.814043\n",
      "0 th epoch,  1420 th batch 0.756497\n",
      "0 th epoch,  1440 th batch 0.909281\n",
      "0 th epoch,  1460 th batch 0.991962\n",
      "0 th epoch,  1480 th batch 1.23332\n",
      "0 th epoch,  1500 th batch 0.944577\n",
      "0 th epoch,  1520 th batch 0.876575\n",
      "0 th epoch,  1540 th batch 0.952353\n",
      "0 th epoch,  1560 th batch 0.789173\n",
      "0 th epoch,  1580 th batch 1.00296\n",
      "0 th epoch,  1600 th batch 1.00287\n",
      "0 th epoch,  1620 th batch 0.834852\n",
      "0 th epoch,  1640 th batch 0.852738\n",
      "0 th epoch,  1660 th batch 0.720962\n",
      "0 th epoch,  1680 th batch 0.805509\n",
      "0 th epoch,  1700 th batch 0.933866\n",
      "0 th epoch,  1720 th batch 0.720983\n",
      "0 th epoch,  1740 th batch 0.724644\n",
      "0 th epoch,  1760 th batch 0.606005\n",
      "0 th epoch,  1780 th batch 0.83905\n",
      "0 th epoch,  1800 th batch 0.737513\n",
      "0 th epoch,  1820 th batch 0.626438\n",
      "0 th epoch,  1840 th batch 1.06692\n",
      "0 th epoch,  1860 th batch 1.02235\n",
      "0 th epoch,  1880 th batch 0.728901\n",
      "0 th epoch,  1900 th batch 0.735788\n",
      "0 th epoch,  1920 th batch 0.695873\n",
      "0 th epoch,  1940 th batch 0.509381\n",
      "0 th epoch,  1960 th batch 0.773792\n",
      "0 th epoch,  1980 th batch 0.727151\n",
      "0 th epoch,  2000 th batch 0.821969\n",
      "0 th epoch,  2020 th batch 0.860538\n",
      "0 th epoch,  2040 th batch 0.733302\n",
      "0 th epoch,  2060 th batch 0.930257\n",
      "0 th epoch,  2080 th batch 0.824059\n",
      "0 th epoch,  2100 th batch 1.07954\n",
      "0 th epoch,  2120 th batch 0.813394\n",
      "0 th epoch,  2140 th batch 0.703822\n",
      "0 th epoch,  2160 th batch 0.471743\n",
      "0 th epoch,  2180 th batch 0.507328\n",
      "0 th epoch,  2200 th batch 0.697236\n",
      "0 th epoch,  2220 th batch 0.724968\n",
      "0 th epoch,  2240 th batch 0.852869\n",
      "1 th epoch,  0 th batch 0.915687\n",
      "1 th epoch,  20 th batch 0.499099\n",
      "1 th epoch,  40 th batch 0.823453\n",
      "1 th epoch,  60 th batch 0.5989\n",
      "1 th epoch,  80 th batch 0.520291\n",
      "1 th epoch,  100 th batch 1.16583\n",
      "1 th epoch,  120 th batch 0.74992\n",
      "1 th epoch,  140 th batch 0.984416\n",
      "1 th epoch,  160 th batch 1.00481\n",
      "1 th epoch,  180 th batch 0.686079\n",
      "1 th epoch,  200 th batch 0.913066\n",
      "1 th epoch,  220 th batch 0.81699\n",
      "1 th epoch,  240 th batch 0.7832\n",
      "1 th epoch,  260 th batch 0.657167\n",
      "1 th epoch,  280 th batch 0.536768\n",
      "1 th epoch,  300 th batch 0.756679\n",
      "1 th epoch,  320 th batch 0.616146\n",
      "1 th epoch,  340 th batch 0.632854\n",
      "1 th epoch,  360 th batch 0.550823\n",
      "1 th epoch,  380 th batch 0.629408\n",
      "1 th epoch,  400 th batch 0.727152\n",
      "1 th epoch,  420 th batch 0.820856\n",
      "1 th epoch,  440 th batch 0.96246\n",
      "1 th epoch,  460 th batch 0.587478\n",
      "1 th epoch,  480 th batch 0.731869\n",
      "1 th epoch,  500 th batch 0.776676\n",
      "1 th epoch,  520 th batch 0.460751\n",
      "1 th epoch,  540 th batch 0.433923\n",
      "1 th epoch,  560 th batch 0.672666\n",
      "1 th epoch,  580 th batch 0.755171\n",
      "1 th epoch,  600 th batch 0.844223\n",
      "1 th epoch,  620 th batch 0.360586\n",
      "1 th epoch,  640 th batch 0.951501\n",
      "1 th epoch,  660 th batch 0.883462\n",
      "1 th epoch,  680 th batch 0.821675\n",
      "1 th epoch,  700 th batch 0.686457\n",
      "1 th epoch,  720 th batch 0.793662\n",
      "1 th epoch,  740 th batch 0.695824\n",
      "1 th epoch,  760 th batch 0.534638\n",
      "1 th epoch,  780 th batch 0.813557\n",
      "1 th epoch,  800 th batch 0.728599\n",
      "1 th epoch,  820 th batch 0.950329\n",
      "1 th epoch,  840 th batch 0.837982\n",
      "1 th epoch,  860 th batch 0.646083\n",
      "1 th epoch,  880 th batch 0.556359\n",
      "1 th epoch,  900 th batch 0.913342\n",
      "1 th epoch,  920 th batch 0.568726\n",
      "1 th epoch,  940 th batch 0.726596\n",
      "1 th epoch,  960 th batch 0.60004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-07d5d7bd16a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mfeed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeed_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplayper\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epoch = 75\n",
    "batch_size = 16\n",
    "\n",
    "displayper = 20\n",
    "\n",
    "m=np.shape(all_data)[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        for j in range(10000):\n",
    "            if len(all_data) <= j*batch_size:\n",
    "                break\n",
    "                \n",
    "            batch_data = all_data[j*batch_size:(j+1)*batch_size]\n",
    "            batch_label = all_label[j*batch_size:(j+1)*batch_size]\n",
    "            feed_train = {X: batch_data, y_: batch_label}\n",
    "        \n",
    "            sess.run(train_step, feed_dict = feed_train)\n",
    "            \n",
    "            if j % displayper == 0:\n",
    "                print(epoch, \"th epoch, \", j, \"th batch\",sess.run(y_loss, feed_dict=feed_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}